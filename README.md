# Disaster_Tweet_NLP

This model uses Word2Vec to embedd the words and GRU to train the model
The main.py also has NB classifier that takes the problem as an n-gram model, but tested out to be less effective than deep learning

You may find the training data here:
https://www.kaggle.com/competitions/nlp-getting-started/data

I trained the model for about 3 epochs and achieved an accuracy of 0.81
